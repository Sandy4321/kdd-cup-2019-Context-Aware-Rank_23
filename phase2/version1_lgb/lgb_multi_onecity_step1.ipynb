{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## lgb多分类，将数据划分为四个城市，然后分开训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total data size: (2304916, 8)\n",
      "raw data columns: click_mode, d, o, pid, plan_time, plans, req_time, sid\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "import json\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from scipy import stats\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from time import gmtime, strftime\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "def split_od(data):\n",
    "    data['o_lng'] = data['o'].apply(lambda x: float(x.split(',')[0])).astype(np.float16)\n",
    "    data['o_lat'] = data['o'].apply(lambda x: float(x.split(',')[1])).astype(np.float16)\n",
    "    data['d_lng'] = data['d'].apply(lambda x: float(x.split(',')[0])).astype(np.float16)\n",
    "    data['d_lat'] = data['d'].apply(lambda x: float(x.split(',')[1])).astype(np.float16)\n",
    "    return data\n",
    "\n",
    "def city_flag(row):\n",
    "    if row[1]>35:       # 北京\n",
    "        return 1\n",
    "    elif row[1]>27.5:   # 上海\n",
    "        return 2\n",
    "    elif row[1]<22.87 and row[0]>113.72:    # 深圳\n",
    "        return 3\n",
    "    else:    # 广州\n",
    "        return 4\n",
    "\n",
    "train_queries1 = pd.read_csv('../data/data_set_phase2/train_queries_phase1.csv')\n",
    "train_queries2 = pd.read_csv('../data/data_set_phase2/train_queries_phase2.csv')\n",
    "train_clicks1 = pd.read_csv('../data/data_set_phase2/train_clicks_phase1.csv')\n",
    "train_clicks2 = pd.read_csv('../data/data_set_phase2/train_clicks_phase2.csv')\n",
    "train_plans1 = pd.read_csv('../data/data_set_phase2/train_plans_phase1.csv')\n",
    "train_plans2 = pd.read_csv('../data/data_set_phase2/train_plans_phase2.csv')\n",
    "gc.collect()\n",
    "\n",
    "train_queries = pd.concat([train_queries1, train_queries2], axis=0)\n",
    "train_plans = pd.concat([train_plans1, train_plans2], axis=0)\n",
    "train_clicks = pd.concat([train_clicks1, train_clicks2], axis=0)\n",
    "\n",
    "test_plans = pd.read_csv('../data/data_set_phase2/test_plans.csv')\n",
    "test_queries = pd.read_csv(\"../data/data_set_phase2/test_queries.csv\")\n",
    "profiles = pd.read_csv('../data/data_set_phase2/profiles.csv')\n",
    "\n",
    "train_data = train_queries.merge(train_clicks, on='sid', how='left')\n",
    "train_data = train_data.merge(train_plans, on='sid', how='left')\n",
    "train_data = train_data.drop(['click_time'], axis=1)\n",
    "train_data['click_mode'] = train_data['click_mode'].fillna(0)\n",
    "\n",
    "test_data = test_queries.merge(test_plans, on='sid', how='left')\n",
    "test_data['click_mode'] = -1\n",
    "\n",
    "data = pd.concat([train_data, test_data], axis=0)\n",
    "data = data.reset_index(drop=True)\n",
    "\n",
    "print('total data size: {}'.format(data.shape))\n",
    "print('raw data columns: {}'.format(', '.join(data.columns)))\n",
    "\n",
    "data = split_od(data)\n",
    "data['city_flag_o'] = data[['o_lng','o_lat']].apply(city_flag, axis=1)\n",
    "data['city_flag_d'] = data[['d_lng','d_lat']].apply(city_flag, axis=1)\n",
    "\n",
    "data = data[data['city_flag_o'] == data['city_flag_d']]\n",
    "data = data.drop(['city_flag_d'],axis=1)\n",
    "\n",
    "beijing = data[data['city_flag_o']==1]\n",
    "shanghai = data[data['city_flag_o']==2]\n",
    "shenzhen = data[data['city_flag_o']==3]\n",
    "guangzhou = data[data['city_flag_o']==4]\n",
    "\n",
    "beijing.to_csv('./processed/data_beijng.csv',index=False)\n",
    "shanghai.to_csv('./processed/data_shanghai.csv',index=False)\n",
    "shenzhen.to_csv('./processed/data_shenzhen.csv',index=False)\n",
    "guangzhou.to_csv('./processed/data_guangzhou.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total data size: (2304916, 8)\n",
      "raw data columns: click_mode, d, o, pid, plan_time, plans, req_time, sid\n"
     ]
    }
   ],
   "source": [
    "def split_od(data):\n",
    "    data['o_lng'] = data['o'].apply(lambda x: float(x.split(',')[0])).astype(np.float16)\n",
    "    data['o_lat'] = data['o'].apply(lambda x: float(x.split(',')[1])).astype(np.float16)\n",
    "    data['d_lng'] = data['d'].apply(lambda x: float(x.split(',')[0])).astype(np.float16)\n",
    "    data['d_lat'] = data['d'].apply(lambda x: float(x.split(',')[1])).astype(np.float16)\n",
    "    return data\n",
    "\n",
    "def city_flag(row):\n",
    "    if row[1]>35:       # 北京\n",
    "        return 1\n",
    "    elif row[1]>27.5:   # 上海\n",
    "        return 2\n",
    "    elif row[1]<22.87 and row[0]>113.72:    # 深圳\n",
    "        return 3\n",
    "    else:    # 广州\n",
    "        return 4\n",
    "\n",
    "train_queries1 = pd.read_csv('../data/data_set_phase2/train_queries_phase1.csv')\n",
    "train_queries2 = pd.read_csv('../data/data_set_phase2/train_queries_phase2.csv')\n",
    "train_clicks1 = pd.read_csv('../data/data_set_phase2/train_clicks_phase1.csv')\n",
    "train_clicks2 = pd.read_csv('../data/data_set_phase2/train_clicks_phase2.csv')\n",
    "train_plans1 = pd.read_csv('../data/data_set_phase2/train_plans_phase1.csv')\n",
    "train_plans2 = pd.read_csv('../data/data_set_phase2/train_plans_phase2.csv')\n",
    "gc.collect()\n",
    "\n",
    "train_queries = pd.concat([train_queries1, train_queries2], axis=0)\n",
    "train_plans = pd.concat([train_plans1, train_plans2], axis=0)\n",
    "train_clicks = pd.concat([train_clicks1, train_clicks2], axis=0)\n",
    "\n",
    "test_plans = pd.read_csv('../data/data_set_phase2/test_plans.csv')\n",
    "test_queries = pd.read_csv(\"../data/data_set_phase2/test_queries.csv\")\n",
    "profiles = pd.read_csv('../data/data_set_phase2/profiles.csv')\n",
    "\n",
    "train_data = train_queries.merge(train_clicks, on='sid', how='left')\n",
    "train_data = train_data.merge(train_plans, on='sid', how='left')\n",
    "train_data = train_data.drop(['click_time'], axis=1)\n",
    "train_data['click_mode'] = train_data['click_mode'].fillna(0)\n",
    "\n",
    "test_data = test_queries.merge(test_plans, on='sid', how='left')\n",
    "test_data['click_mode'] = -1\n",
    "\n",
    "data = pd.concat([train_data, test_data], axis=0)\n",
    "data = data.reset_index(drop=True)\n",
    "\n",
    "print('total data size: {}'.format(data.shape))\n",
    "print('raw data columns: {}'.format(', '.join(data.columns)))\n",
    "\n",
    "data = split_od(data)\n",
    "data['city_flag_o'] = data[['o_lng','o_lat']].apply(city_flag, axis=1)\n",
    "data['city_flag_d'] = data[['d_lng','d_lat']].apply(city_flag, axis=1)\n",
    "\n",
    "shen_guang = data[data['city_flag_o']>2].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1124625, 24) (1124625, 14)\n",
      "(1124625, 37)\n",
      "(555523, 37) (569040, 37)\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../data/colla_filter_feat/colla_filter_shenzhen.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-ae936290f766>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshenzhen\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mguangzhou\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m \u001b[0mshenzhen\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcolla_col\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'../data/colla_filter_feat/colla_filter_shenzhen.csv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[0mguangzhou\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcolla_col\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'../data/colla_filter_feat/colla_filter_guangzhou.csv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\envs\\python35\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mto_csv\u001b[1;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, tupleize_cols, date_format, doublequote, escapechar, decimal)\u001b[0m\n\u001b[0;32m   3018\u001b[0m                                  \u001b[0mdoublequote\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdoublequote\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3019\u001b[0m                                  escapechar=escapechar, decimal=decimal)\n\u001b[1;32m-> 3020\u001b[1;33m         \u001b[0mformatter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3021\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3022\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mpath_or_buf\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\envs\\python35\\lib\\site-packages\\pandas\\io\\formats\\csvs.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    155\u001b[0m             f, handles = _get_handle(self.path_or_buf, self.mode,\n\u001b[0;32m    156\u001b[0m                                      \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 157\u001b[1;33m                                      compression=self.compression)\n\u001b[0m\u001b[0;32m    158\u001b[0m             \u001b[0mclose\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    159\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\envs\\python35\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36m_get_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text)\u001b[0m\n\u001b[0;32m    422\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    423\u001b[0m             \u001b[1;31m# Python 3 and encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 424\u001b[1;33m             \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnewline\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    425\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mis_text\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    426\u001b[0m             \u001b[1;31m# Python 3 and no explicit encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../data/colla_filter_feat/colla_filter_shenzhen.csv'"
     ]
    }
   ],
   "source": [
    "colla_filter = pd.read_csv('./xietong_feature_shenzhen.csv')\n",
    "print(colla_filter.shape, shen_guang.shape)\n",
    "gc.collect()\n",
    "\n",
    "colla_filter = colla_filter.iloc[:,1:]\n",
    "colla_col = colla_filter.columns.tolist()\n",
    "shen_guang = pd.concat([shen_guang, colla_filter], axis=1)\n",
    "\n",
    "print(shen_guang.shape)\n",
    "\n",
    "shen_guang = shen_guang[shen_guang['city_flag_o'] == shen_guang['city_flag_d']]\n",
    "\n",
    "shenzhen = shen_guang[shen_guang['city_flag_d']==3]\n",
    "guangzhou = shen_guang[shen_guang['city_flag_d']==4]\n",
    "\n",
    "print(shenzhen.shape, guangzhou.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "shenzhen[colla_col].to_csv('./xietong_divide_shenzhen.csv', index=False)\n",
    "guangzhou[colla_col].to_csv('./xietong_divide_guangzhou.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
